"""
Vulnerability Analyzer

AI-powered vulnerability analysis for bug bounty hunting.
Analyzes BurpSuite findings, identifies patterns, and suggests
additional attack vectors with intelligent prioritization.
"""

import json
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class Severity(Enum):
    """Vulnerability severity levels"""
    CRITICAL = "Critical"
    HIGH = "High"
    MEDIUM = "Medium"
    LOW = "Low"
    INFO = "Informational"


class VulnerabilityType(Enum):
    """Common vulnerability types"""
    SQL_INJECTION = "SQL Injection"
    XSS = "Cross-Site Scripting (XSS)"
    CSRF = "Cross-Site Request Forgery (CSRF)"
    SSRF = "Server-Side Request Forgery (SSRF)"
    RCE = "Remote Code Execution (RCE)"
    LFI = "Local File Inclusion (LFI)"
    RFI = "Remote File Inclusion (RFI)"
    XXE = "XML External Entity (XXE)"
    IDOR = "Insecure Direct Object Reference (IDOR)"
    BROKEN_AUTH = "Broken Authentication"
    SENSITIVE_DATA = "Sensitive Data Exposure"
    XXS_STORED = "Stored XSS"
    XXS_REFLECTED = "Reflected XSS"
    XXS_DOM = "DOM-Based XSS"
    OPEN_REDIRECT = "Open Redirect"
    CLICKJACKING = "Clickjacking"
    CORS_MISCONFIGURATION = "CORS Misconfiguration"
    SECURITY_MISCONFIGURATION = "Security Misconfiguration"


@dataclass
class Vulnerability:
    """Discovered vulnerability"""
    title: str
    vuln_type: VulnerabilityType
    severity: Severity
    url: str
    
    # Details
    description: str = ""
    impact: str = ""
    remediation: str = ""
    
    # Evidence
    poc: str = ""  # Proof of concept
    request: str = ""
    response: str = ""
    parameter: str = ""
    payload: str = ""
    
    # Classification
    cvss_score: float = 0.0
    cwe_id: Optional[str] = None
    owasp_category: Optional[str] = None
    
    # Metadata
    discovered_at: datetime = field(default_factory=datetime.now)
    verified: bool = False
    false_positive: bool = False
    notes: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary"""
        return {
            "title": self.title,
            "type": self.vuln_type.value,
            "severity": self.severity.value,
            "url": self.url,
            "description": self.description,
            "impact": self.impact,
            "remediation": self.remediation,
            "poc": self.poc,
            "cvss_score": self.cvss_score,
            "cwe_id": self.cwe_id,
            "verified": self.verified,
            "discovered_at": self.discovered_at.isoformat()
        }


class VulnerabilityAnalyzer:
    """
    AI-powered vulnerability analyzer
    
    Features:
    - Analyzes BurpSuite scan results
    - Identifies vulnerability patterns
    - Suggests additional attack vectors
    - Prioritizes findings by severity
    - Generates proof-of-concept exploits
    - Provides remediation advice
    """
    
    def __init__(self, ai_client=None):
        """
        Initialize vulnerability analyzer
        
        Args:
            ai_client: AI client for intelligent analysis
        """
        self.ai_client = ai_client
        
        # Vulnerability patterns
        self.vuln_patterns = {
            'sql_injection': [
                "error in your SQL syntax",
                "mysql_fetch",
                "ORA-01756",
                "Microsoft OLE DB Provider for SQL Server",
                "Warning: mysql",
                "PostgreSQL query failed"
            ],
            'xss': [
                "<script>", "javascript:", "onerror=", "onload=",
                "eval(", "alert(", "prompt(", "confirm("
            ],
            'lfi': [
                "/etc/passwd", "boot.ini", "win.ini",
                "root:x:", "[boot loader]"
            ],
            'xxe': [
                "<!ENTITY", "<!DOCTYPE", "SYSTEM"
            ]
        }
    
    def parse_burp_issue(self, issue: Dict[str, Any]) -> Vulnerability:
        """
        Parse BurpSuite issue into Vulnerability object
        
        Args:
            issue: BurpSuite issue dictionary
            
        Returns:
            Vulnerability object
        """
        # Map severity
        severity_map = {
            'high': Severity.HIGH,
            'medium': Severity.MEDIUM,
            'low': Severity.LOW,
            'info': Severity.INFO,
            'information': Severity.INFO
        }
        
        severity_str = issue.get('severity', 'info').lower()
        severity = severity_map.get(severity_str, Severity.INFO)
        
        # Map type
        issue_type_name = issue.get('issue_type', {}).get('name', 'Unknown')
        vuln_type = self._map_vulnerability_type(issue_type_name)
        
        # Create vulnerability
        vuln = Vulnerability(
            title=issue_type_name,
            vuln_type=vuln_type,
            severity=severity,
            url=issue.get('origin', ''),
            description=issue.get('issue_detail', {}).get('issue_description', ''),
            impact=issue.get('issue_detail', {}).get('issue_background', ''),
            remediation=issue.get('issue_detail', {}).get('remediation_background', ''),
            cvss_score=issue.get('cvss_score', 0.0)
        )
        
        # Extract evidence
        evidence = issue.get('evidence', [])
        if evidence:
            first_evidence = evidence[0]
            vuln.request = first_evidence.get('request_response', {}).get('request', '')
            vuln.response = first_evidence.get('request_response', {}).get('response', '')
        
        return vuln
    
    def _map_vulnerability_type(self, issue_name: str) -> VulnerabilityType:
        """Map BurpSuite issue name to VulnerabilityType"""
        issue_lower = issue_name.lower()
        
        if 'sql injection' in issue_lower:
            return VulnerabilityType.SQL_INJECTION
        elif 'cross-site scripting' in issue_lower or 'xss' in issue_lower:
            if 'stored' in issue_lower:
                return VulnerabilityType.XXS_STORED
            elif 'reflected' in issue_lower:
                return VulnerabilityType.XXS_REFLECTED
            elif 'dom' in issue_lower:
                return VulnerabilityType.XXS_DOM
            return VulnerabilityType.XSS
        elif 'csrf' in issue_lower:
            return VulnerabilityType.CSRF
        elif 'ssrf' in issue_lower:
            return VulnerabilityType.SSRF
        elif 'remote code' in issue_lower or 'rce' in issue_lower:
            return VulnerabilityType.RCE
        elif 'file inclusion' in issue_lower:
            if 'local' in issue_lower or 'lfi' in issue_lower:
                return VulnerabilityType.LFI
            return VulnerabilityType.RFI
        elif 'xxe' in issue_lower or 'xml external' in issue_lower:
            return VulnerabilityType.XXE
        elif 'idor' in issue_lower or 'insecure direct' in issue_lower:
            return VulnerabilityType.IDOR
        elif 'authentication' in issue_lower or 'session' in issue_lower:
            return VulnerabilityType.BROKEN_AUTH
        elif 'open redirect' in issue_lower:
            return VulnerabilityType.OPEN_REDIRECT
        elif 'clickjacking' in issue_lower:
            return VulnerabilityType.CLICKJACKING
        elif 'cors' in issue_lower:
            return VulnerabilityType.CORS_MISCONFIGURATION
        else:
            return VulnerabilityType.SECURITY_MISCONFIGURATION
    
    def analyze_vulnerabilities(
        self,
        vulnerabilities: List[Vulnerability]
    ) -> Dict[str, Any]:
        """
        Analyze list of vulnerabilities and provide insights
        
        Args:
            vulnerabilities: List of vulnerabilities
            
        Returns:
            Analysis report with statistics and recommendations
        """
        if not vulnerabilities:
            return {
                "total": 0,
                "by_severity": {},
                "by_type": {},
                "recommendations": []
            }
        
        # Count by severity
        by_severity = {}
        for vuln in vulnerabilities:
            severity = vuln.severity.value
            by_severity[severity] = by_severity.get(severity, 0) + 1
        
        # Count by type
        by_type = {}
        for vuln in vulnerabilities:
            vuln_type = vuln.vuln_type.value
            by_type[vuln_type] = by_type.get(vuln_type, 0) + 1
        
        # Prioritize
        critical_high = [v for v in vulnerabilities if v.severity in [Severity.CRITICAL, Severity.HIGH]]
        
        # Generate recommendations
        recommendations = []
        
        if len(critical_high) > 0:
            recommendations.append(f"URGENT: Address {len(critical_high)} critical/high severity issues immediately")
        
        # Type-specific recommendations
        if VulnerabilityType.SQL_INJECTION.value in by_type:
            recommendations.append("SQL Injection found - Use parameterized queries immediately")
        if VulnerabilityType.XSS.value in by_type or VulnerabilityType.XXS_STORED.value in by_type:
            recommendations.append("XSS found - Implement proper output encoding and CSP")
        if VulnerabilityType.RCE.value in by_type:
            recommendations.append("CRITICAL: Remote Code Execution possible - Patch immediately")
        
        return {
            "total": len(vulnerabilities),
            "by_severity": by_severity,
            "by_type": by_type,
            "critical_high_count": len(critical_high),
            "critical_high_urls": list(set([v.url for v in critical_high]))[:10],
            "recommendations": recommendations
        }
    
    async def ai_analyze_vulnerability(
        self,
        vuln: Vulnerability
    ) -> Dict[str, Any]:
        """
        Use AI to analyze vulnerability and suggest exploitation
        
        Args:
            vuln: Vulnerability to analyze
            
        Returns:
            AI analysis with exploitation suggestions
        """
        if not self.ai_client:
            return {"error": "AI client not configured"}
        
        prompt = f"""Analyze this security vulnerability and provide detailed exploitation guidance:

Title: {vuln.title}
Type: {vuln.vuln_type.value}
Severity: {vuln.severity.value}
URL: {vuln.url}

Description:
{vuln.description}

Impact:
{vuln.impact}

Please provide:
1. Detailed explanation of the vulnerability
2. Step-by-step exploitation guide
3. Advanced exploitation techniques
4. Potential chained attacks
5. Recommended proof-of-concept
6. Remediation steps for developers
7. Bounty payout estimate (low/medium/high)

Focus on providing actionable exploitation steps for bug bounty reporting.
"""
        
        try:
            from src.cognitive.llm.model_loader import ModelLoader
            loader = ModelLoader()
            
            response = loader.generate(
                prompt=prompt,
                task_type="analysis",
                max_tokens=1500
            )
            
            return {
                "analysis": response,
                "vulnerability": vuln.to_dict()
            }
        except Exception as e:
            logger.error(f"AI vulnerability analysis failed: {e}")
            return {"error": str(e)}
    
    async def suggest_attack_vectors(
        self,
        url: str,
        technologies: List[str]
    ) -> List[Dict[str, str]]:
        """
        AI-powered attack vector suggestions
        
        Args:
            url: Target URL
            technologies: Detected technologies
            
        Returns:
            List of suggested attack vectors
        """
        if not self.ai_client:
            return []
        
        prompt = f"""Given this web application target, suggest specific attack vectors to test:

URL: {url}
Technologies: {', '.join(technologies)}

Provide a list of specific attack vectors to test, including:
1. URL/parameter to test
2. Vulnerability type to look for
3. Test payload
4. Expected vulnerable behavior

Format as JSON array of objects with keys: target, vuln_type, payload, indicator
"""
        
        try:
            from src.cognitive.llm.model_loader import ModelLoader
            loader = ModelLoader()
            
            response = loader.generate(
                prompt=prompt,
                task_type="code",
                max_tokens=1000
            )
            
            # Try to parse JSON from response
            import re
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if json_match:
                attack_vectors = json.loads(json_match.group())
                return attack_vectors
            
            return []
        except Exception as e:
            logger.error(f"AI attack vector suggestion failed: {e}")
            return []
    
    def filter_false_positives(
        self,
        vulnerabilities: List[Vulnerability]
    ) -> List[Vulnerability]:
        """
        Filter out likely false positives
        
        Args:
            vulnerabilities: List of vulnerabilities
            
        Returns:
            Filtered list with likely true positives
        """
        filtered = []
        
        for vuln in vulnerabilities:
            # Skip if already marked as false positive
            if vuln.false_positive:
                continue
            
            # Low severity info issues are often false positives
            if vuln.severity == Severity.INFO and "missing" not in vuln.title.lower():
                continue
            
            # Some common false positives
            fp_keywords = [
                "Password field with autocomplete enabled",
                "Private IP addresses disclosed",
                "Email addresses disclosed"
            ]
            
            is_fp = any(keyword in vuln.title for keyword in fp_keywords)
            if is_fp:
                vuln.false_positive = True
                vuln.notes = "Likely false positive - low impact"
                continue
            
            filtered.append(vuln)
        
        logger.info(f"Filtered {len(vulnerabilities) - len(filtered)} false positives")
        return filtered


# Example usage
if __name__ == "__main__":
    analyzer = VulnerabilityAnalyzer()
    
    # Example BurpSuite issue
    burp_issue = {
        "issue_type": {"name": "SQL injection"},
        "severity": "high",
        "origin": "https://example.com/search?q=test",
        "cvss_score": 9.1,
        "issue_detail": {
            "issue_description": "SQL injection in search parameter",
            "issue_background": "Allows database access and data exfiltration",
            "remediation_background": "Use parameterized queries"
        }
    }
    
    vuln = analyzer.parse_burp_issue(burp_issue)
    
    print(f"Vulnerability: {vuln.title}")
    print(f"Type: {vuln.vuln_type.value}")
    print(f"Severity: {vuln.severity.value}")
    print(f"URL: {vuln.url}")
    print(f"CVSS: {vuln.cvss_score}")
