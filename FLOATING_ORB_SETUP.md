# üéØ Aether AI Floating Orb - Setup Complete

## ‚úÖ Current Status

**All features working:**
- ‚úÖ Floating orb UI (80px, draggable)
- ‚úÖ Natural voice output (Edge TTS - en-IN-NeerjaNeural)
- ‚úÖ Local voice input (Whisper base model)
- ‚úÖ Click orb ‚Üí Voice listening (5 seconds)
- ‚úÖ Drag top edge ‚Üí Move window
- ‚úÖ Backend logging (USER SAID / AETHER SAID)

## üöÄ Quick Start

### 1. Start Aether (Backend + Frontend)

```cmd
cd C:\Users\nandk\.zenflow\worktrees\aether-00f9\aether-ai-repo
START_AETHER.bat
```

**Wait 1-2 minutes** for backend to load (43 AI components).

### 2. Use Floating Orb

- **Click orb center** ‚Üí Start voice listening
- **Speak for 5 seconds** ‚Üí Auto-transcribe with local Whisper
- **Response plays** ‚Üí Natural Indian English voice
- **Drag top edge** ‚Üí Move orb around screen

### 3. Check Backend Logs

Backend terminal shows:
```
USER SAID: hello how are you
AETHER SAID: You said: hello how are you
```

### 4. Frontend Console (Debugging)

Press **F12** in Electron window:
```javascript
Sending audio for transcription...
Transcription received: {text: "..."}
Setting speaking status...
Speaking: You said: ...
Speech completed successfully
```

## ‚öôÔ∏è Configuration

### Voice Settings (.env)

```env
# Voice Output (TTS)
VOICE_PROVIDER=edge
VOICE_NAME=en-IN-NeerjaNeural
VOICE_RATE=165

# Voice Input (STT)
STT_PROVIDER=local
STT_MODEL=base
```

### AI Provider Priority

```env
FALLBACK_PROVIDER=fireworks
```

**Provider order:**
1. Fireworks
2. Groq
3. Anthropic
4. Google
5. OpenRouter
6. OpenAI (last)

## üõ†Ô∏è Key Files Modified

### Backend
- `src/config.py` - Added STT_PROVIDER setting
- `src/api/routes/voice.py` - Added USER SAID / AETHER SAID logging
- `src/cognitive/llm/model_router.py` - Reordered provider priority

### Frontend
- `ui/main.js` - Window size 130x130px
- `ui/src/FloatingOrb.jsx` - Clickable orb + drag handle + detailed logging
- `ui/src/FloatingOrb.css` - 80px orb styling

### Config
- `.env` - Updated voice settings (STT_PROVIDER=local, FALLBACK_PROVIDER=fireworks)

## üêõ Troubleshooting

### Issue: Orb not listening
**Check:** Backend logs for `POST /api/v1/voice/transcribe`
**Fix:** Restart backend, check mic permissions

### Issue: No response audio
**Check:** F12 console for "Speech error"
**Fix:** Check system volume, speaker connection

### Issue: OpenAI quota error
**Solution:** Already fixed! Using local Whisper (no API calls)

### Issue: Drag not working
**Solution:** Drag the **top edge** (40px strip), not center

## üìä Performance

- **Backend startup:** 45-60 seconds (43 components)
- **Voice input:** 3-5 seconds (local Whisper base model)
- **Voice output:** 0.3 seconds (Edge TTS cached)
- **Window size:** 130x130px (80px orb + 25px padding)

## üîß Manual Backend Start (Alternative)

```cmd
cd C:\Users\nandk\.zenflow\worktrees\aether-00f9\aether-ai-repo
venv\Scripts\python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

## üîß Manual Frontend Start (Alternative)

```cmd
cd C:\Users\nandk\.zenflow\worktrees\aether-00f9\aether-ai-repo\ui
npm run dev
```

## üìù Next Steps

1. Test voice input/output working
2. Check backend logs showing conversation
3. Verify orb dragging works
4. Test multiple voice interactions

---

**Session completed:** 2026-02-19
**Version:** v3.0.3 with Floating Orb
